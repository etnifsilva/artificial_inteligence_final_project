{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70981603-a521-4a9b-8d72-72913d56f4f6",
   "metadata": {},
   "source": [
    "### 1. Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5204ba87-9499-45ea-ba59-10deb562a062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder\n",
    "from stable_baselines3 import HerReplayBuffer, SAC\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold, CallbackList\n",
    "from stable_baselines3.her.her_replay_buffer import DictReplayBuffer\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from typing import Any, Callable\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f61cec-f78c-4026-a590-5e7ca5d256cc",
   "metadata": {},
   "source": [
    "### 2. Testing Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4638ddf4-0015-4380-a892-282ca1d7e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"FetchPickAndPlace-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72b101f9-b762-4583-9cb6-7dd9224baac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56011e0b-902e-4bba-8984-425a2df576dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Monitor(gym.make(environment_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92f6c00d-7190-47a6-809b-2d73460937ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=-2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "964f327a-4584-4bb7-8f38-984ff7f7da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_callback = EvalCallback(env, best_model_save_path=log_path,\n",
    "                             log_path=log_path, eval_freq=12000, callback_on_new_best=callback_on_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2ad6897-74c3-4223-b92b-6f11f8cb5436",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11762951, -0.34023935, -0.44053447, -0.18788737], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88136ca3-d31a-445a-99b3-4c0932cf728d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('achieved_goal',\n",
       "              array([ 0.7213227, -0.9876719,  1.1325431], dtype=float32)),\n",
       "             ('desired_goal',\n",
       "              array([0.46884996, 0.13244456, 1.2508638 ], dtype=float32)),\n",
       "             ('observation',\n",
       "              array([-0.3212221 , -0.45945266,  0.67389446,  0.70562613,  0.6267838 ,\n",
       "                     -0.8263457 , -0.27775422, -0.59260035, -0.38706642, -0.04525652,\n",
       "                      1.8288016 ,  1.503531  ,  1.3220016 , -3.5423703 , -0.42946556,\n",
       "                      0.98484045,  0.61054313,  0.9122507 ,  0.64001834, -0.5057297 ,\n",
       "                      0.52541274,  0.44773683,  0.418074  ,  1.2150637 ,  0.43818712],\n",
       "                    dtype=float32))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f461e2ee-7df4-48f7-b242-52d75e717150",
   "metadata": {},
   "source": [
    "### 3. Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b74fa500-ff6e-4d11-b718-204575e43e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5100e828-a672-4ad8-ba82-cd1b7ce397e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sampled_goal = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "272dbd8b-86a6-456c-924f-eb7ca94130cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_log = os.path.join('tensor_board')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6d3412f-c8df-4aaa-9b2c-9b26418f73a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_schedule(initial_value: float) -> Callable[[float], float]:\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        if(progress_remaining >= 3/4):\n",
    "            return initial_value\n",
    "        if(progress_remaining >= 2/4):\n",
    "            return initial_value / 2\n",
    "        if(progress_remaining >= 1/4):\n",
    "            return initial_value / 4\n",
    "        else:\n",
    "            return initial_value / 8\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "897a6225-d618-40c9-bff4-5a2b3bf32b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAC(\n",
    "    \"MultiInputPolicy\",\n",
    "    env,\n",
    "    replay_buffer_class=HerReplayBuffer,\n",
    "    replay_buffer_kwargs=dict(\n",
    "      n_sampled_goal=n_sampled_goal,\n",
    "      goal_selection_strategy=\"future\",\n",
    "      online_sampling=True,\n",
    "    ),\n",
    "    verbose=0,\n",
    "    buffer_size=int(1e6),\n",
    "    learning_rate=linear_schedule(1e-4),\n",
    "    gamma=0.95,\n",
    "    batch_size=256,\n",
    "    policy_kwargs=dict(net_arch=[256, 256, 256]),\n",
    "    tensorboard_log=tensorboard_log\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1d8c307-c0b1-4018-ab0b-cf611a3fe8b0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 09:47:36.092253: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/etni/dev/pos/lib/python3.8/site-packages/cv2/../../lib64::/home/etni/.mujoco/mujoco210/bin\n",
      "2022-04-05 09:47:36.092313: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=12000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "New best mean reward!\n",
      "Eval num_timesteps=24000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "Eval num_timesteps=36000, episode_reward=-40.00 +/- 20.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "New best mean reward!\n",
      "Eval num_timesteps=48000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "Eval num_timesteps=60000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "Eval num_timesteps=72000, episode_reward=-30.00 +/- 24.49\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 40.00%\n",
      "New best mean reward!\n",
      "Eval num_timesteps=84000, episode_reward=-41.00 +/- 18.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "Eval num_timesteps=96000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "Eval num_timesteps=108000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "Eval num_timesteps=120000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "Eval num_timesteps=132000, episode_reward=-40.00 +/- 20.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "Eval num_timesteps=144000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "Eval num_timesteps=156000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "Eval num_timesteps=168000, episode_reward=-43.40 +/- 13.20\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "Eval num_timesteps=180000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "Eval num_timesteps=192000, episode_reward=-40.00 +/- 20.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "Eval num_timesteps=204000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "Eval num_timesteps=216000, episode_reward=-40.00 +/- 20.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "Eval num_timesteps=228000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "Eval num_timesteps=240000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "Eval num_timesteps=252000, episode_reward=-40.00 +/- 20.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "Eval num_timesteps=264000, episode_reward=-45.40 +/- 9.20\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "Eval num_timesteps=276000, episode_reward=-41.00 +/- 15.62\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "Eval num_timesteps=288000, episode_reward=-44.40 +/- 9.33\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "Eval num_timesteps=300000, episode_reward=-40.00 +/- 20.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "Eval num_timesteps=312000, episode_reward=-50.00 +/- 0.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "Eval num_timesteps=324000, episode_reward=-36.80 +/- 15.84\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 40.00%\n",
      "Eval num_timesteps=336000, episode_reward=-19.60 +/- 17.49\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "New best mean reward!\n",
      "Eval num_timesteps=348000, episode_reward=-15.40 +/- 17.73\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "New best mean reward!\n",
      "Eval num_timesteps=360000, episode_reward=-31.80 +/- 22.29\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 40.00%\n",
      "Eval num_timesteps=372000, episode_reward=-39.80 +/- 18.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "Eval num_timesteps=384000, episode_reward=-39.80 +/- 19.90\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "Eval num_timesteps=396000, episode_reward=-32.40 +/- 21.59\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 40.00%\n",
      "Eval num_timesteps=408000, episode_reward=-30.00 +/- 18.37\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 40.00%\n",
      "Eval num_timesteps=420000, episode_reward=-43.60 +/- 12.80\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "Eval num_timesteps=432000, episode_reward=-41.40 +/- 17.20\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "Eval num_timesteps=444000, episode_reward=-42.00 +/- 15.01\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "Eval num_timesteps=456000, episode_reward=-24.00 +/- 18.07\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=468000, episode_reward=-40.00 +/- 20.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 20.00%\n",
      "Eval num_timesteps=480000, episode_reward=-36.80 +/- 16.28\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 40.00%\n",
      "Eval num_timesteps=492000, episode_reward=-42.80 +/- 9.17\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 0.00%\n",
      "Eval num_timesteps=504000, episode_reward=-40.40 +/- 15.51\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 40.00%\n",
      "Eval num_timesteps=516000, episode_reward=-20.20 +/- 16.73\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=528000, episode_reward=-24.60 +/- 20.76\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 60.00%\n",
      "Eval num_timesteps=540000, episode_reward=-19.00 +/- 16.15\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=552000, episode_reward=-7.60 +/- 8.55\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "New best mean reward!\n",
      "Eval num_timesteps=564000, episode_reward=-25.00 +/- 17.57\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 60.00%\n",
      "Eval num_timesteps=576000, episode_reward=-14.00 +/- 3.79\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=588000, episode_reward=-23.80 +/- 19.10\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=600000, episode_reward=-20.40 +/- 15.21\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=612000, episode_reward=-12.40 +/- 4.76\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=624000, episode_reward=-18.20 +/- 16.10\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=636000, episode_reward=-7.20 +/- 2.14\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "New best mean reward!\n",
      "Eval num_timesteps=648000, episode_reward=-9.20 +/- 2.14\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=660000, episode_reward=-8.40 +/- 3.44\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=672000, episode_reward=-8.80 +/- 5.91\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=684000, episode_reward=-10.00 +/- 4.94\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=696000, episode_reward=-19.80 +/- 14.65\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=708000, episode_reward=-6.20 +/- 1.72\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "New best mean reward!\n",
      "Eval num_timesteps=720000, episode_reward=-8.60 +/- 1.62\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=732000, episode_reward=-11.20 +/- 4.71\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=744000, episode_reward=-7.60 +/- 5.16\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=756000, episode_reward=-9.20 +/- 2.32\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=768000, episode_reward=-8.20 +/- 6.40\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=780000, episode_reward=-7.80 +/- 1.72\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=792000, episode_reward=-10.40 +/- 4.50\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=804000, episode_reward=-8.20 +/- 1.72\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=816000, episode_reward=-10.80 +/- 2.86\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=828000, episode_reward=-9.40 +/- 0.49\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=840000, episode_reward=-17.40 +/- 15.46\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=852000, episode_reward=-10.00 +/- 5.37\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=864000, episode_reward=-10.00 +/- 1.90\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=876000, episode_reward=-11.20 +/- 2.14\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=888000, episode_reward=-8.80 +/- 4.87\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=900000, episode_reward=-9.40 +/- 4.50\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=912000, episode_reward=-10.80 +/- 3.60\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=924000, episode_reward=-7.20 +/- 3.76\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=936000, episode_reward=-9.00 +/- 2.37\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=948000, episode_reward=-6.60 +/- 2.15\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=960000, episode_reward=-16.00 +/- 10.73\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=972000, episode_reward=-18.20 +/- 15.94\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=984000, episode_reward=-8.80 +/- 4.83\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=996000, episode_reward=-6.80 +/- 2.79\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1008000, episode_reward=-7.80 +/- 1.94\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1020000, episode_reward=-8.60 +/- 2.73\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1032000, episode_reward=-10.40 +/- 4.08\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1044000, episode_reward=-8.60 +/- 2.73\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1056000, episode_reward=-11.00 +/- 4.05\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1068000, episode_reward=-7.40 +/- 1.36\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1080000, episode_reward=-9.40 +/- 4.32\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1092000, episode_reward=-8.60 +/- 5.43\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1104000, episode_reward=-8.20 +/- 4.53\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1116000, episode_reward=-9.00 +/- 2.61\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1128000, episode_reward=-7.20 +/- 4.53\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1140000, episode_reward=-8.20 +/- 4.02\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1152000, episode_reward=-9.60 +/- 2.58\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1164000, episode_reward=-9.40 +/- 4.67\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1176000, episode_reward=-8.40 +/- 3.61\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1188000, episode_reward=-8.80 +/- 2.23\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1200000, episode_reward=-6.80 +/- 1.33\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1212000, episode_reward=-8.20 +/- 3.43\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1224000, episode_reward=-10.60 +/- 5.46\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1236000, episode_reward=-9.00 +/- 4.60\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1248000, episode_reward=-7.00 +/- 2.10\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1260000, episode_reward=-8.40 +/- 4.59\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1272000, episode_reward=-11.00 +/- 5.18\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1284000, episode_reward=-7.40 +/- 3.72\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1296000, episode_reward=-7.40 +/- 3.88\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1308000, episode_reward=-10.20 +/- 2.56\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1320000, episode_reward=-7.00 +/- 3.74\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1332000, episode_reward=-10.40 +/- 2.58\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1344000, episode_reward=-22.60 +/- 17.97\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=1356000, episode_reward=-9.40 +/- 3.20\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1368000, episode_reward=-11.80 +/- 2.64\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1380000, episode_reward=-10.60 +/- 4.36\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1392000, episode_reward=-8.40 +/- 4.41\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1404000, episode_reward=-10.80 +/- 3.71\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1416000, episode_reward=-12.80 +/- 11.72\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1428000, episode_reward=-8.00 +/- 2.10\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1440000, episode_reward=-9.60 +/- 4.50\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1452000, episode_reward=-9.40 +/- 3.38\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1464000, episode_reward=-8.60 +/- 3.14\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1476000, episode_reward=-12.80 +/- 3.66\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1488000, episode_reward=-5.80 +/- 3.49\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "New best mean reward!\n",
      "Eval num_timesteps=1500000, episode_reward=-7.80 +/- 1.72\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1512000, episode_reward=-7.20 +/- 4.02\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1524000, episode_reward=-12.60 +/- 3.61\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1536000, episode_reward=-9.20 +/- 2.79\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1548000, episode_reward=-9.00 +/- 3.52\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1560000, episode_reward=-7.80 +/- 1.83\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1572000, episode_reward=-15.40 +/- 5.89\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1584000, episode_reward=-9.80 +/- 3.60\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1596000, episode_reward=-10.00 +/- 4.34\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1608000, episode_reward=-6.60 +/- 3.44\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1620000, episode_reward=-5.20 +/- 3.19\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "New best mean reward!\n",
      "Eval num_timesteps=1632000, episode_reward=-9.60 +/- 3.44\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1644000, episode_reward=-9.60 +/- 2.65\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1656000, episode_reward=-6.60 +/- 3.83\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1668000, episode_reward=-11.80 +/- 3.12\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1680000, episode_reward=-8.40 +/- 1.50\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1692000, episode_reward=-9.20 +/- 3.71\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1704000, episode_reward=-8.00 +/- 2.10\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1716000, episode_reward=-8.20 +/- 3.66\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1728000, episode_reward=-6.80 +/- 3.71\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1740000, episode_reward=-7.00 +/- 2.19\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1752000, episode_reward=-10.40 +/- 2.87\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1764000, episode_reward=-7.80 +/- 4.12\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1776000, episode_reward=-9.40 +/- 4.22\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1788000, episode_reward=-8.80 +/- 2.64\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1800000, episode_reward=-8.80 +/- 2.48\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1812000, episode_reward=-8.60 +/- 3.26\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1824000, episode_reward=-8.60 +/- 2.58\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1836000, episode_reward=-9.60 +/- 1.96\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1848000, episode_reward=-10.20 +/- 1.60\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1860000, episode_reward=-7.00 +/- 1.41\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1872000, episode_reward=-9.00 +/- 3.29\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1884000, episode_reward=-9.00 +/- 4.05\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1896000, episode_reward=-8.80 +/- 4.07\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1908000, episode_reward=-7.00 +/- 2.76\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1920000, episode_reward=-8.60 +/- 4.88\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1932000, episode_reward=-7.40 +/- 3.01\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1944000, episode_reward=-11.80 +/- 2.14\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1956000, episode_reward=-7.00 +/- 2.76\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1968000, episode_reward=-7.80 +/- 4.26\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1980000, episode_reward=-10.20 +/- 3.66\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=1992000, episode_reward=-6.40 +/- 4.50\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2004000, episode_reward=-7.80 +/- 4.35\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2016000, episode_reward=-18.40 +/- 13.71\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=2028000, episode_reward=-11.00 +/- 4.05\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2040000, episode_reward=-6.20 +/- 2.99\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2052000, episode_reward=-7.40 +/- 2.33\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2064000, episode_reward=-7.00 +/- 3.29\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2076000, episode_reward=-6.80 +/- 4.17\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2088000, episode_reward=-8.60 +/- 3.20\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2100000, episode_reward=-8.80 +/- 3.43\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2112000, episode_reward=-6.80 +/- 0.75\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2124000, episode_reward=-8.60 +/- 2.42\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2136000, episode_reward=-5.80 +/- 3.54\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2148000, episode_reward=-9.80 +/- 0.98\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2160000, episode_reward=-8.00 +/- 2.28\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2172000, episode_reward=-5.60 +/- 2.94\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2184000, episode_reward=-8.60 +/- 3.77\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2196000, episode_reward=-8.40 +/- 3.44\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2208000, episode_reward=-8.00 +/- 2.68\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2220000, episode_reward=-5.40 +/- 1.62\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2232000, episode_reward=-8.00 +/- 1.10\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2244000, episode_reward=-8.40 +/- 2.73\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2256000, episode_reward=-7.80 +/- 2.79\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2268000, episode_reward=-9.40 +/- 5.12\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2280000, episode_reward=-10.60 +/- 3.38\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2292000, episode_reward=-7.80 +/- 4.53\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2304000, episode_reward=-9.40 +/- 3.44\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2316000, episode_reward=-9.60 +/- 3.61\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2328000, episode_reward=-6.00 +/- 4.15\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2340000, episode_reward=-5.00 +/- 3.03\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "New best mean reward!\n",
      "Eval num_timesteps=2352000, episode_reward=-7.40 +/- 1.85\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2364000, episode_reward=-10.80 +/- 3.54\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2376000, episode_reward=-7.40 +/- 4.03\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2388000, episode_reward=-9.60 +/- 2.87\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2400000, episode_reward=-8.80 +/- 1.33\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2412000, episode_reward=-6.80 +/- 3.87\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2424000, episode_reward=-9.20 +/- 2.23\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2436000, episode_reward=-5.00 +/- 2.83\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2448000, episode_reward=-6.00 +/- 3.52\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2460000, episode_reward=-9.20 +/- 2.32\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2472000, episode_reward=-8.20 +/- 2.40\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2484000, episode_reward=-9.80 +/- 2.23\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2496000, episode_reward=-10.40 +/- 2.73\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2508000, episode_reward=-12.00 +/- 2.10\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2520000, episode_reward=-10.80 +/- 2.04\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2532000, episode_reward=-4.60 +/- 2.42\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "New best mean reward!\n",
      "Eval num_timesteps=2544000, episode_reward=-6.40 +/- 3.77\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2556000, episode_reward=-7.60 +/- 5.24\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2568000, episode_reward=-10.20 +/- 4.49\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2580000, episode_reward=-8.80 +/- 3.37\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2592000, episode_reward=-10.00 +/- 3.74\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2604000, episode_reward=-7.20 +/- 5.19\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2616000, episode_reward=-7.40 +/- 2.33\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2628000, episode_reward=-9.00 +/- 2.97\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2640000, episode_reward=-8.20 +/- 3.49\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2652000, episode_reward=-9.20 +/- 5.15\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2664000, episode_reward=-8.40 +/- 3.38\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2676000, episode_reward=-8.60 +/- 4.13\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2688000, episode_reward=-15.80 +/- 17.24\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=2700000, episode_reward=-6.20 +/- 2.64\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2712000, episode_reward=-7.00 +/- 2.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2724000, episode_reward=-8.00 +/- 2.28\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2736000, episode_reward=-17.60 +/- 16.35\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=2748000, episode_reward=-7.40 +/- 2.87\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2760000, episode_reward=-12.60 +/- 2.15\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2772000, episode_reward=-9.40 +/- 2.58\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2784000, episode_reward=-10.00 +/- 3.16\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2796000, episode_reward=-8.20 +/- 1.17\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2808000, episode_reward=-16.60 +/- 16.79\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=2820000, episode_reward=-7.40 +/- 3.26\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2832000, episode_reward=-7.60 +/- 3.07\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2844000, episode_reward=-8.60 +/- 2.24\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2856000, episode_reward=-10.80 +/- 4.26\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2868000, episode_reward=-10.00 +/- 3.10\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2880000, episode_reward=-9.80 +/- 2.71\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2892000, episode_reward=-9.60 +/- 3.26\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2904000, episode_reward=-8.80 +/- 3.19\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2916000, episode_reward=-10.20 +/- 3.54\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2928000, episode_reward=-9.00 +/- 2.61\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2940000, episode_reward=-7.80 +/- 3.82\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2952000, episode_reward=-9.20 +/- 2.71\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2964000, episode_reward=-5.80 +/- 3.12\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2976000, episode_reward=-7.60 +/- 4.03\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=2988000, episode_reward=-7.60 +/- 0.80\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3000000, episode_reward=-8.80 +/- 3.54\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3012000, episode_reward=-11.20 +/- 4.17\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3024000, episode_reward=-7.60 +/- 4.32\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3036000, episode_reward=-10.00 +/- 5.02\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3048000, episode_reward=-8.80 +/- 1.33\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3060000, episode_reward=-8.20 +/- 2.40\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3072000, episode_reward=-8.60 +/- 2.87\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3084000, episode_reward=-8.60 +/- 4.22\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3096000, episode_reward=-9.40 +/- 3.44\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3108000, episode_reward=-13.00 +/- 18.64\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=3120000, episode_reward=-8.80 +/- 2.14\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3132000, episode_reward=-7.60 +/- 5.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3144000, episode_reward=-9.40 +/- 2.15\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3156000, episode_reward=-8.20 +/- 4.26\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3168000, episode_reward=-5.00 +/- 4.65\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3180000, episode_reward=-6.40 +/- 3.93\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3192000, episode_reward=-8.40 +/- 4.22\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3204000, episode_reward=-8.00 +/- 4.15\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3216000, episode_reward=-7.20 +/- 3.19\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3228000, episode_reward=-6.60 +/- 1.02\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3240000, episode_reward=-8.00 +/- 2.61\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3252000, episode_reward=-11.20 +/- 4.07\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3264000, episode_reward=-8.60 +/- 3.72\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3276000, episode_reward=-4.80 +/- 2.64\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3288000, episode_reward=-7.60 +/- 2.50\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3300000, episode_reward=-8.20 +/- 4.83\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3312000, episode_reward=-8.60 +/- 3.50\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3324000, episode_reward=-10.60 +/- 4.80\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3336000, episode_reward=-10.40 +/- 4.18\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3348000, episode_reward=-10.00 +/- 2.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3360000, episode_reward=-9.80 +/- 3.31\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3372000, episode_reward=-8.00 +/- 3.29\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3384000, episode_reward=-19.00 +/- 15.77\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=3396000, episode_reward=-7.00 +/- 2.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3408000, episode_reward=-7.60 +/- 3.38\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3420000, episode_reward=-11.60 +/- 1.74\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3432000, episode_reward=-5.60 +/- 3.26\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3444000, episode_reward=-7.60 +/- 2.65\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3456000, episode_reward=-7.80 +/- 3.06\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3468000, episode_reward=-8.60 +/- 2.94\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3480000, episode_reward=-9.20 +/- 1.60\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3492000, episode_reward=-6.80 +/- 2.23\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3504000, episode_reward=-9.20 +/- 2.79\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3516000, episode_reward=-7.00 +/- 1.26\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3528000, episode_reward=-6.40 +/- 1.36\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3540000, episode_reward=-10.60 +/- 2.58\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3552000, episode_reward=-4.40 +/- 2.58\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "New best mean reward!\n",
      "Eval num_timesteps=3564000, episode_reward=-9.60 +/- 3.07\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3576000, episode_reward=-7.40 +/- 2.06\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3588000, episode_reward=-7.60 +/- 2.87\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3600000, episode_reward=-9.60 +/- 5.24\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3612000, episode_reward=-9.60 +/- 4.50\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3624000, episode_reward=-8.60 +/- 4.08\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3636000, episode_reward=-15.40 +/- 14.81\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=3648000, episode_reward=-18.00 +/- 16.41\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 80.00%\n",
      "Eval num_timesteps=3660000, episode_reward=-8.00 +/- 1.41\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3672000, episode_reward=-8.60 +/- 1.02\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3684000, episode_reward=-9.20 +/- 2.56\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3696000, episode_reward=-7.60 +/- 1.20\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3708000, episode_reward=-6.80 +/- 1.17\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3720000, episode_reward=-10.00 +/- 2.76\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3732000, episode_reward=-6.20 +/- 3.43\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3744000, episode_reward=-10.20 +/- 3.31\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3756000, episode_reward=-7.60 +/- 5.28\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3768000, episode_reward=-6.80 +/- 3.97\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3780000, episode_reward=-6.80 +/- 3.66\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3792000, episode_reward=-6.80 +/- 2.71\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3804000, episode_reward=-5.60 +/- 3.01\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3816000, episode_reward=-9.80 +/- 3.82\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3828000, episode_reward=-8.40 +/- 1.02\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3840000, episode_reward=-6.80 +/- 2.48\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3852000, episode_reward=-9.20 +/- 2.32\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3864000, episode_reward=-6.60 +/- 3.56\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3876000, episode_reward=-9.40 +/- 2.94\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3888000, episode_reward=-9.40 +/- 2.58\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3900000, episode_reward=-10.40 +/- 3.07\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3912000, episode_reward=-8.20 +/- 3.43\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3924000, episode_reward=-7.60 +/- 4.67\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3936000, episode_reward=-8.00 +/- 4.20\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3948000, episode_reward=-10.80 +/- 3.19\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3960000, episode_reward=-7.60 +/- 3.07\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3972000, episode_reward=-11.20 +/- 4.07\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3984000, episode_reward=-6.40 +/- 5.00\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n",
      "Eval num_timesteps=3996000, episode_reward=-6.40 +/- 4.13\n",
      "Episode length: 50.00 +/- 0.00\n",
      "Success rate: 100.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x7ffce1adcc10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(int(4e6), callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0893cd81-4834-4a9a-92df-43f675501ce6",
   "metadata": {},
   "source": [
    "### 4. Evaluating Last Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9c185db-b626-4b57-af9f-9fc68cbbf5ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2daf94-a364-4991-b06d-d53303f1c8bf",
   "metadata": {},
   "source": [
    "### 5. Reloading Best Model and Recording Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "544b9e2d-9034-4744-947c-a90ecac1c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15540c81-6895-4b81-a0ec-0efd73ba39fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAC.load(os.path.join(log_path, 'best_model.zip'), env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67fbac86-5527-44b3-bcef-e5ab923e92bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = os.path.join('video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2bd48c1d-f666-4ba8-92c9-560fa6822591",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_length = 12000\n",
    "\n",
    "env = VecVideoRecorder(env,\n",
    "                       video_path,\n",
    "                       record_video_trigger=lambda x: x == 0,\n",
    "                       video_length=video_length,\n",
    "                       name_prefix=f\"final-agent-{environment_name}\")\n",
    "\n",
    "result = evaluate_policy(model, env, n_eval_episodes=10, render=False)\n",
    "# Save the video\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f4091bd-59a8-49c2-90e8-8e26354378dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n",
      "Score: -8.2\n"
     ]
    }
   ],
   "source": [
    "result = evaluate_policy(model, env, n_eval_episodes=50, render=True)\n",
    "env.close()\n",
    "print('Score: {}'.format(result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e549b42a-63e6-4606-b4bd-dfe9de54be4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
